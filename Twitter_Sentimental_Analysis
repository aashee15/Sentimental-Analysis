{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentimental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted By : Ansh Kumar Garg \n",
    "\n",
    "Section : ML\n",
    "\n",
    "University Roll : 2015014    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Used for data analysis\n",
    "import numpy as np # Used \n",
    "import re # Used for regular expressions \n",
    "import nltk # Used for text manipulation \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') # This will ignore all warnings  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing a CSV file to DataFrame \n",
    "train = pd.read_csv(r\"C:\\Users\\Ansh Garg\\Desktop\\Projects\\Ansh_Twitter_Sentimental_Analysis_project\\Data Set\\train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\Ansh Garg\\Desktop\\Projects\\Ansh_Twitter_Sentimental_Analysis_project\\Data Set\\test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining both the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "0    1    0.0   @user when a father is dysfunctional and is s...\n",
       "1    2    0.0  @user @user thanks for #lyft credit i can't us...\n",
       "2    3    0.0                                bihday your majesty\n",
       "3    4    0.0  #model   i love u take with u all the time in ...\n",
       "4    5    0.0             factsguide: society now    #motivation\n",
       "5    6    0.0  [2/2] huge fan fare and big talking before the...\n",
       "6    7    0.0   @user camping tomorrow @user @user @user @use...\n",
       "7    8    0.0  the next school year is the year for exams.ð...\n",
       "8    9    0.0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9   10    0.0   @user @user welcome here !  i'm   it's so #gr...\n",
       "10  11    0.0   â #ireland consumer price index (mom) climb...\n",
       "11  12    0.0  we are so selfish. #orlando #standwithorlando ...\n",
       "12  13    0.0  i get to see my daddy today!!   #80days #getti...\n",
       "13  14    1.0  @user #cnn calls #michigan middle school 'buil...\n",
       "14  15    1.0  no comment!  in #australia   #opkillingbay #se...\n",
       "15  16    0.0  ouch...junior is angryð#got7 #junior #yugyo...\n",
       "16  17    0.0  i am thankful for having a paner. #thankful #p...\n",
       "17  18    1.0                             retweet if you agree! \n",
       "18  19    0.0  its #friday! ð smiles all around via ig use...\n",
       "19  20    0.0  as we all know, essential oils are not made of..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining test and train and storing in dataset and checking the head\n",
    "dataset = train.append(test, ignore_index = True) #This will combine test and trai dataset\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father dysfunctional selfish drags kids i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks lyft credit can't cause they don't offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love take with time urð±!!! ððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2/2] huge fare talking before they leave. cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>camping tomorrow dannyâ¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>next school year year exams.ð¯ can't think a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>won!!! love land!!! allin cavs champions cleve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>welcome here it's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ireland consumer price index (mom) climbed fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>selfish. orlando standwithorlando pulseshootin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>daddy today!! 80days gettingfed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>calls michigan middle school 'build wall' chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comment! australia opkillingbay seashepherd he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ouch...junior angryðgot7 junior yugyoem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thankful having paner. thankful positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>retweet agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>friday! ð smiles around user: cookies make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>know, essential oils made chemicals.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "0    1    0.0  when father dysfunctional selfish drags kids i...\n",
       "1    2    0.0  thanks lyft credit can't cause they don't offe...\n",
       "2    3    0.0                                bihday your majesty\n",
       "3    4    0.0  model love take with time urð±!!! ððð...\n",
       "4    5    0.0                     factsguide: society motivation\n",
       "5    6    0.0  [2/2] huge fare talking before they leave. cha...\n",
       "6    7    0.0                          camping tomorrow dannyâ¦\n",
       "7    8    0.0  next school year year exams.ð¯ can't think a...\n",
       "8    9    0.0  won!!! love land!!! allin cavs champions cleve...\n",
       "9   10    0.0                                  welcome here it's\n",
       "10  11    0.0  ireland consumer price index (mom) climbed fro...\n",
       "11  12    0.0  selfish. orlando standwithorlando pulseshootin...\n",
       "12  13    0.0                    daddy today!! 80days gettingfed\n",
       "13  14    1.0  calls michigan middle school 'build wall' chan...\n",
       "14  15    1.0  comment! australia opkillingbay seashepherd he...\n",
       "15  16    0.0         ouch...junior angryðgot7 junior yugyoem\n",
       "16  17    0.0           thankful having paner. thankful positive\n",
       "17  18    1.0                                     retweet agree!\n",
       "18  19    0.0  friday! ð smiles around user: cookies make ...\n",
       "19  20    0.0               know, essential oils made chemicals."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a function with name clean and doing preprocessing \n",
    "def clean(text):\n",
    "    text = text.lower() #Converting all tweets to lower case\n",
    "    text = re.sub(r'@[a-z0-9]+', '',text) #Removing all the twitter handles\n",
    "    text = re.sub(r'#', '',text) #Removing '#' Symbols\n",
    "    text = re.sub(r'RT[\\s]+', '',text) #Removing RT \n",
    "    return text\n",
    "dataset['tweet'] = dataset['tweet'].apply(clean)\n",
    "\n",
    "# Removing the stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "dataset['tweet'] = dataset['tweet'].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father dysfunctional selfish drags kids i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks lyft credit can't cause they don't offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love take with time urð±!!! ððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2/2] huge fare talking before they leave. cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>camping tomorrow dannyâ¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>next school year year exams.ð¯ can't think a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>won!!! love land!!! allin cavs champions cleve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>welcome here it's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1    0.0  when father dysfunctional selfish drags kids i...\n",
       "1   2    0.0  thanks lyft credit can't cause they don't offe...\n",
       "2   3    0.0                                bihday your majesty\n",
       "3   4    0.0  model love take with time urð±!!! ððð...\n",
       "4   5    0.0                     factsguide: society motivation\n",
       "5   6    0.0  [2/2] huge fare talking before they leave. cha...\n",
       "6   7    0.0                          camping tomorrow dannyâ¦\n",
       "7   8    0.0  next school year year exams.ð¯ can't think a...\n",
       "8   9    0.0  won!!! love land!!! allin cavs champions cleve...\n",
       "9  10    0.0                                  welcome here it's"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.fillna(0)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer = CountVectorizer(max_df = 0.90, min_df=2, max_features = 1000, stop_words = 'english')\n",
    "bag_of_words = bow_vectorizer.fit_transform(dataset['tweet'])\n",
    "bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, x_test, ytrain, y_test = train_test_split(bag_of_words, dataset['label'], random_state=1,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of xtrain is : (36869, 1000)\n",
      "shape of ytrain is : (36869,)\n",
      "shape of x_test is : (12290, 1000)\n",
      "shape of y_test is : (12290,)\n"
     ]
    }
   ],
   "source": [
    "# checking shape of dataset\n",
    "print(\"shape of xtrain is :\",xtrain.shape)\n",
    "print(\"shape of ytrain is :\",ytrain.shape)\n",
    "print(\"shape of x_test is :\",x_test.shape)\n",
    "print(\"shape of y_test is :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Naive_Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB  classifier on training set: {:.2f} 0.9482763297078847\n",
      "Accuracy of NB classifier on test set: {:.2f} 0.9449145646867372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11400,   333],\n",
       "       [  344,   213]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "NB = MultinomialNB().fit(xtrain, ytrain)\n",
    "pred = NB.predict(x_test)\n",
    "print('Accuracy of NB  classifier on training set: {:.2f}' ,format(NB.score(xtrain, ytrain)))\n",
    "print('Accuracy of NB classifier on test set: {:.2f}' ,format(NB.score(x_test, y_test)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic classifier on training set {:.2f} 0.9593425370907809\n",
      "Accuracy of Logistic classifier on test set {:.2f} 0.9567127746135069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11657,    76],\n",
       "       [  456,   101]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "logreg = LogisticRegression().fit(xtrain, ytrain)\n",
    "pred = logreg.predict(x_test)\n",
    "print('Accuracy of Logistic classifier on training set {:.2f}' ,format(logreg.score(xtrain, ytrain)))\n",
    "print('Accuracy of Logistic classifier on test set {:.2f}' ,format(logreg.score(x_test, y_test)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
